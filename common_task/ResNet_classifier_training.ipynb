{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f511bec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:42:50.043796Z",
     "iopub.status.busy": "2025-03-26T21:42:50.043410Z",
     "iopub.status.idle": "2025-03-26T21:42:59.795733Z",
     "shell.execute_reply": "2025-03-26T21:42:59.795027Z"
    },
    "papermill": {
     "duration": 9.758996,
     "end_time": "2025-03-26T21:42:59.797281",
     "exception": false,
     "start_time": "2025-03-26T21:42:50.038285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d36fdc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-26T21:42:59.805344Z",
     "iopub.status.busy": "2025-03-26T21:42:59.804940Z",
     "iopub.status.idle": "2025-03-26T21:42:59.808549Z",
     "shell.execute_reply": "2025-03-26T21:42:59.807767Z"
    },
    "papermill": {
     "duration": 0.008826,
     "end_time": "2025-03-26T21:42:59.809771",
     "exception": false,
     "start_time": "2025-03-26T21:42:59.800945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define dataset class\n",
    "# class LensDataset(Dataset):\n",
    "#     def __init__(self, root_dir, transform=None):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "#         self.classes = [\"no\", \"sphere\", \"vort\"]\n",
    "#         self.image_paths = []\n",
    "#         self.labels = []\n",
    "        \n",
    "#         # Load file paths and labels\n",
    "#         for label, class_name in enumerate(self.classes):\n",
    "#             class_dir = os.path.join(root_dir, class_name)\n",
    "#             for file in os.listdir(class_dir):\n",
    "#                 if file.endswith('.npy'):\n",
    "#                     self.image_paths.append(os.path.join(class_dir, file))\n",
    "#                     self.labels.append(label)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         image_path = self.image_paths[idx]\n",
    "#         label = self.labels[idx]\n",
    "        \n",
    "#         # Load image from .npy file\n",
    "#         image = np.load(image_path)\n",
    "#         image = np.stack([image] * 3, axis=-1)\n",
    "#         image = torch.from_numpy(image).float()\n",
    "\n",
    "            \n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a853db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:42:59.816879Z",
     "iopub.status.busy": "2025-03-26T21:42:59.816615Z",
     "iopub.status.idle": "2025-03-26T21:42:59.819423Z",
     "shell.execute_reply": "2025-03-26T21:42:59.818873Z"
    },
    "papermill": {
     "duration": 0.007535,
     "end_time": "2025-03-26T21:42:59.820555",
     "exception": false,
     "start_time": "2025-03-26T21:42:59.813020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define transformations\n",
    "# transform = transforms.Compose([\n",
    "#     # transforms.Resize((224, 224)),  # Resize for DenseNet/ResNet\n",
    "#     # transforms.RandomHorizontalFlip(),\n",
    "#     # transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # Load train and validation datasets\n",
    "# train_dataset = LensDataset(\"/kaggle/input/multiclass-classification-gravitational-lensing/dataset/train\", transform=transform)\n",
    "# val_dataset = LensDataset(\"/kaggle/input/multiclass-classification-gravitational-lensing/dataset/val\", transform=transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# # Function to display sample images\n",
    "# def show_class_samples(dataset, title, num_images=5):\n",
    "#     fig, axes = plt.subplots(len(dataset.classes), num_images, figsize=(15, 10))\n",
    "#     for class_idx, class_name in enumerate(dataset.classes):\n",
    "#         class_samples = [dataset[i] for i in range(len(dataset)) if dataset.labels[i] == class_idx][:num_images]\n",
    "#         for j, (image, label) in enumerate(class_samples):\n",
    "#             axes[class_idx, j].imshow(image.permute(1, 2, 0), cmap=\"gray\")\n",
    "#             axes[class_idx, j].set_title(f\"{title}: {class_name}\")\n",
    "#             axes[class_idx, j].axis(\"off\")\n",
    "#     plt.show()\n",
    "# # Display samples from train and val set\n",
    "# show_class_samples(train_dataset, \"Train Set\")\n",
    "# show_class_samples(val_dataset, \"Validation Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3f92e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:42:59.827255Z",
     "iopub.status.busy": "2025-03-26T21:42:59.827056Z",
     "iopub.status.idle": "2025-03-26T21:43:00.697599Z",
     "shell.execute_reply": "2025-03-26T21:43:00.696711Z"
    },
    "papermill": {
     "duration": 0.87562,
     "end_time": "2025-03-26T21:43:00.699231",
     "exception": false,
     "start_time": "2025-03-26T21:42:59.823611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpechetti-1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "\n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80217698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:00.707267Z",
     "iopub.status.busy": "2025-03-26T21:43:00.707022Z",
     "iopub.status.idle": "2025-03-26T21:43:02.338590Z",
     "shell.execute_reply": "2025-03-26T21:43:02.337558Z"
    },
    "papermill": {
     "duration": 1.637334,
     "end_time": "2025-03-26T21:43:02.340333",
     "exception": false,
     "start_time": "2025-03-26T21:43:00.702999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250326_214300-pq76j0ki\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdainty-waterfall-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/pechetti-1/lens_classification\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/pechetti-1/lens_classification/runs/pq76j0ki\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"lens_classification\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da5b6a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:02.349442Z",
     "iopub.status.busy": "2025-03-26T21:43:02.349186Z",
     "iopub.status.idle": "2025-03-26T21:43:04.980969Z",
     "shell.execute_reply": "2025-03-26T21:43:04.980219Z"
    },
    "papermill": {
     "duration": 2.637896,
     "end_time": "2025-03-26T21:43:04.982462",
     "exception": false,
     "start_time": "2025-03-26T21:43:02.344566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110M/110M [00:00<00:00, 206MB/s] \n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 217MB/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "densenet = models.densenet161(pretrained=True)\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the classifier for 3 classes\n",
    "densenet.classifier = nn.Sequential(\n",
    "    nn.Linear(2208, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.Dropout(p=0.33),\n",
    "    nn.Linear(1024, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.Dropout(p=0.33),\n",
    "    nn.Linear(64, 3)\n",
    ")\n",
    "\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Linear(resnet.fc.in_features, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(1024),\n",
    "    nn.Dropout(p=0.33),\n",
    "    nn.Linear(1024, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.Dropout(p=0.33),\n",
    "    nn.Linear(64, 3)\n",
    ")\n",
    "\n",
    "densenet.to(device)\n",
    "resnet.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_densenet = optim.Adam(densenet.parameters(), lr=1e-4)\n",
    "optimizer_resnet = optim.Adam(resnet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac9d047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:04.993359Z",
     "iopub.status.busy": "2025-03-26T21:43:04.993090Z",
     "iopub.status.idle": "2025-03-26T21:43:04.996565Z",
     "shell.execute_reply": "2025-03-26T21:43:04.995955Z"
    },
    "papermill": {
     "duration": 0.010382,
     "end_time": "2025-03-26T21:43:04.997928",
     "exception": false,
     "start_time": "2025-03-26T21:43:04.987546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler_resnet = optim.lr_scheduler.StepLR(optimizer_resnet, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee30ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:05.008275Z",
     "iopub.status.busy": "2025-03-26T21:43:05.008035Z",
     "iopub.status.idle": "2025-03-26T21:43:05.014805Z",
     "shell.execute_reply": "2025-03-26T21:43:05.014189Z"
    },
    "papermill": {
     "duration": 0.013251,
     "end_time": "2025-03-26T21:43:05.016074",
     "exception": false,
     "start_time": "2025-03-26T21:43:05.002823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sections_densenet = {\n",
    "    \"classifier\": (list(densenet.classifier.parameters()),5),\n",
    "    \"features_late\": (list(densenet.features[10:].parameters()),3),\n",
    "    \"features_mid\": (list(densenet.features[6:10].parameters()),7),\n",
    "    \"features_early\": (list(densenet.features[:6].parameters()),15)\n",
    "}\n",
    "\n",
    "sections_resnet = {\n",
    "    \"fc\": (list(resnet.fc.parameters()),3),\n",
    "    \"layer4\": (list(resnet.layer4.parameters()),5),\n",
    "    \"layer3\": (list(resnet.layer3.parameters()),5),\n",
    "    \"layer2\": (list(resnet.layer2.parameters()),5),\n",
    "    \"layer1\": (list(resnet.layer1.parameters()),5),\n",
    "    \"conv1\": (list(resnet.conv1.parameters()),7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0715e527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:05.026242Z",
     "iopub.status.busy": "2025-03-26T21:43:05.025989Z",
     "iopub.status.idle": "2025-03-26T21:43:05.033331Z",
     "shell.execute_reply": "2025-03-26T21:43:05.032742Z"
    },
    "papermill": {
     "duration": 0.013938,
     "end_time": "2025-03-26T21:43:05.034623",
     "exception": false,
     "start_time": "2025-03-26T21:43:05.020685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, name, sections):\n",
    "    model.train()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for section_name, (section_params,num_epochs) in sections.items():\n",
    "        for param in section_params:\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        for epoch in range(num_epochs):  # Train each section until saturation\n",
    "            running_loss = 0.0\n",
    "            correct, total = 0, 0\n",
    "            model.train()\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            train_acc = correct / total\n",
    "\n",
    "            if (epoch + 1) % 2 == 0:\n",
    "                torch.save(model.state_dict(), f\"{name}_{section_name}_epoch{epoch+1}.pth\")\n",
    "                 \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                    val_total += labels.size(0)\n",
    "            val_loss /= len(val_loader)\n",
    "            val_acc = val_correct / val_total\n",
    "            \n",
    "            wandb.log({\n",
    "                f\"{name} Train Loss\": train_loss,\n",
    "                f\"{name} Train Accuracy\": train_acc,\n",
    "                f\"{name} Validation Loss\": val_loss,\n",
    "                f\"{name} Validation Accuracy\": val_acc\n",
    "            })\n",
    "            \n",
    "            print(f\"{name} {section_name} - Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "            scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3ad88e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:05.044408Z",
     "iopub.status.busy": "2025-03-26T21:43:05.044198Z",
     "iopub.status.idle": "2025-03-26T21:43:05.050367Z",
     "shell.execute_reply": "2025-03-26T21:43:05.049770Z"
    },
    "papermill": {
     "duration": 0.012166,
     "end_time": "2025-03-26T21:43:05.051402",
     "exception": false,
     "start_time": "2025-03-26T21:43:05.039236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LensDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = [\"no\", \"sphere\", \"vort\"]\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for file in os.listdir(class_dir):\n",
    "                if file.endswith('.npy'):\n",
    "                    self.image_paths.append(os.path.join(class_dir, file))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = np.load(image_path).astype(np.float32)\n",
    "        \n",
    "        # Ensure the image has 2D or 3D shape compatible with PyTorch\n",
    "        if image.ndim == 2:  # Grayscale image\n",
    "            image = np.stack([image] * 3, axis=0)  # Convert to 3 channels (C, H, W)\n",
    "        elif image.ndim == 3 and image.shape[0] == 1:  # Single-channel image\n",
    "            image = np.squeeze(image, axis=0)  # Remove the extra channel dimension\n",
    "            image = np.stack([image] * 3, axis=0)  # Convert to 3 channels\n",
    "        \n",
    "        if self.transform:\n",
    "            image = torch.tensor(image)  # Convert to tensor\n",
    "            image = self.transform(image)  # Apply transformations\n",
    "        \n",
    "        return image.to(device), torch.tensor(label, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf5691c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:05.061302Z",
     "iopub.status.busy": "2025-03-26T21:43:05.061053Z",
     "iopub.status.idle": "2025-03-26T21:43:05.425570Z",
     "shell.execute_reply": "2025-03-26T21:43:05.424596Z"
    },
    "papermill": {
     "duration": 0.371261,
     "end_time": "2025-03-26T21:43:05.427197",
     "exception": false,
     "start_time": "2025-03-26T21:43:05.055936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for DenseNet/ResNet\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load train and validation datasets\n",
    "train_dataset = LensDataset(r\"/kaggle/input/multiclass-classification-gravitational-lensing/dataset/train\", transform=transform)\n",
    "val_dataset = LensDataset(r\"/kaggle/input/multiclass-classification-gravitational-lensing/dataset/val\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "addde741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:05.438121Z",
     "iopub.status.busy": "2025-03-26T21:43:05.437833Z",
     "iopub.status.idle": "2025-03-26T21:43:05.441212Z",
     "shell.execute_reply": "2025-03-26T21:43:05.440389Z"
    },
    "papermill": {
     "duration": 0.010066,
     "end_time": "2025-03-26T21:43:05.442464",
     "exception": false,
     "start_time": "2025-03-26T21:43:05.432398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_model(densenet, optimizer_densenet, \"DenseNet\", sections_densenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ebc3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T21:43:05.452629Z",
     "iopub.status.busy": "2025-03-26T21:43:05.452350Z",
     "iopub.status.idle": "2025-03-26T23:21:02.466762Z",
     "shell.execute_reply": "2025-03-26T23:21:02.465887Z"
    },
    "papermill": {
     "duration": 5877.026502,
     "end_time": "2025-03-26T23:21:02.473693",
     "exception": false,
     "start_time": "2025-03-26T21:43:05.447191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet fc - Epoch 1: Train Loss=1.1449, Train Acc=0.3591, Val Loss=1.0896, Val Acc=0.3941\n",
      "ResNet fc - Epoch 2: Train Loss=1.1050, Train Acc=0.3838, Val Loss=1.0823, Val Acc=0.3883\n",
      "ResNet fc - Epoch 3: Train Loss=1.0886, Train Acc=0.3967, Val Loss=1.0756, Val Acc=0.4033\n",
      "ResNet layer4 - Epoch 1: Train Loss=1.0549, Train Acc=0.4319, Val Loss=1.0312, Val Acc=0.4605\n",
      "ResNet layer4 - Epoch 2: Train Loss=0.9827, Train Acc=0.5066, Val Loss=0.9707, Val Acc=0.5080\n",
      "ResNet layer4 - Epoch 3: Train Loss=0.9192, Train Acc=0.5578, Val Loss=0.9769, Val Acc=0.5177\n",
      "ResNet layer4 - Epoch 4: Train Loss=0.8511, Train Acc=0.6034, Val Loss=0.9811, Val Acc=0.5152\n",
      "ResNet layer4 - Epoch 5: Train Loss=0.7571, Train Acc=0.6632, Val Loss=1.0649, Val Acc=0.5017\n",
      "ResNet layer3 - Epoch 1: Train Loss=0.8397, Train Acc=0.6114, Val Loss=0.9180, Val Acc=0.5507\n",
      "ResNet layer3 - Epoch 2: Train Loss=0.7315, Train Acc=0.6794, Val Loss=0.8530, Val Acc=0.5981\n",
      "ResNet layer3 - Epoch 3: Train Loss=0.5304, Train Acc=0.7966, Val Loss=0.8342, Val Acc=0.6268\n",
      "ResNet layer3 - Epoch 4: Train Loss=0.4117, Train Acc=0.8545, Val Loss=0.8936, Val Acc=0.6172\n",
      "ResNet layer3 - Epoch 5: Train Loss=0.3199, Train Acc=0.8947, Val Loss=0.9723, Val Acc=0.6061\n",
      "ResNet layer2 - Epoch 1: Train Loss=0.2476, Train Acc=0.9243, Val Loss=1.0087, Val Acc=0.5977\n",
      "ResNet layer2 - Epoch 2: Train Loss=0.1910, Train Acc=0.9471, Val Loss=1.0473, Val Acc=0.6081\n",
      "ResNet layer2 - Epoch 3: Train Loss=0.1465, Train Acc=0.9601, Val Loss=1.1200, Val Acc=0.6169\n",
      "ResNet layer2 - Epoch 4: Train Loss=0.1173, Train Acc=0.9697, Val Loss=1.1691, Val Acc=0.6096\n",
      "ResNet layer2 - Epoch 5: Train Loss=0.0928, Train Acc=0.9766, Val Loss=1.1951, Val Acc=0.6280\n",
      "ResNet layer1 - Epoch 1: Train Loss=0.0817, Train Acc=0.9788, Val Loss=1.3619, Val Acc=0.5989\n",
      "ResNet layer1 - Epoch 2: Train Loss=0.0708, Train Acc=0.9807, Val Loss=1.3035, Val Acc=0.6172\n",
      "ResNet layer1 - Epoch 3: Train Loss=0.0553, Train Acc=0.9864, Val Loss=1.3417, Val Acc=0.6171\n",
      "ResNet layer1 - Epoch 4: Train Loss=0.0484, Train Acc=0.9895, Val Loss=1.3094, Val Acc=0.6163\n",
      "ResNet layer1 - Epoch 5: Train Loss=0.0422, Train Acc=0.9914, Val Loss=1.3411, Val Acc=0.6135\n",
      "ResNet conv1 - Epoch 1: Train Loss=0.0396, Train Acc=0.9926, Val Loss=1.3335, Val Acc=0.6168\n",
      "ResNet conv1 - Epoch 2: Train Loss=0.0357, Train Acc=0.9935, Val Loss=1.3389, Val Acc=0.6177\n",
      "ResNet conv1 - Epoch 3: Train Loss=0.0371, Train Acc=0.9931, Val Loss=1.3629, Val Acc=0.6105\n",
      "ResNet conv1 - Epoch 4: Train Loss=0.0328, Train Acc=0.9945, Val Loss=1.3668, Val Acc=0.6345\n",
      "ResNet conv1 - Epoch 5: Train Loss=0.0295, Train Acc=0.9951, Val Loss=1.4042, Val Acc=0.6155\n",
      "ResNet conv1 - Epoch 6: Train Loss=0.0315, Train Acc=0.9945, Val Loss=1.4047, Val Acc=0.6228\n",
      "ResNet conv1 - Epoch 7: Train Loss=0.0280, Train Acc=0.9957, Val Loss=1.3802, Val Acc=0.6113\n"
     ]
    }
   ],
   "source": [
    "train_model(resnet, optimizer_resnet, scheduler_resnet, \"ResNet\", sections_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cad8274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T23:21:02.486452Z",
     "iopub.status.busy": "2025-03-26T23:21:02.486212Z",
     "iopub.status.idle": "2025-03-26T23:21:02.733153Z",
     "shell.execute_reply": "2025-03-26T23:21:02.732471Z"
    },
    "papermill": {
     "duration": 0.254867,
     "end_time": "2025-03-26T23:21:02.734507",
     "exception": false,
     "start_time": "2025-03-26T23:21:02.479640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef22ca9",
   "metadata": {
    "papermill": {
     "duration": 0.009431,
     "end_time": "2025-03-26T23:21:02.752521",
     "exception": false,
     "start_time": "2025-03-26T23:21:02.743090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a4404",
   "metadata": {
    "papermill": {
     "duration": 0.005811,
     "end_time": "2025-03-26T23:21:02.822450",
     "exception": false,
     "start_time": "2025-03-26T23:21:02.816639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277768ce",
   "metadata": {
    "papermill": {
     "duration": 0.005563,
     "end_time": "2025-03-26T23:21:02.833952",
     "exception": false,
     "start_time": "2025-03-26T23:21:02.828389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6968549,
     "sourceId": 11166824,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5897.430359,
   "end_time": "2025-03-26T23:21:04.767080",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-26T21:42:47.336721",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
