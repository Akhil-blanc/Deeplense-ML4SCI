{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class LensDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = [\"no\", \"sphere\", \"vort\"]\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load file paths and labels\n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for file in os.listdir(class_dir):\n",
    "                if file.endswith('.npy'):\n",
    "                    self.image_paths.append(os.path.join(class_dir, file))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        \n",
    "        image = np.load(image_path)\n",
    "        \n",
    "        # Ensure the image has 2D or 3D shape compatible with PIL\n",
    "        if image.ndim == 2:  # Grayscale image\n",
    "            image = np.stack([image] * 3, axis=-1)  # Convert to RGB by duplicating channels\n",
    "        elif image.ndim == 3 and image.shape[0] == 1:  # Single-channel image\n",
    "            image = np.squeeze(image, axis=0)  # Remove the channel dimension\n",
    "            image = np.stack([image] * 3, axis=-1)  # Convert to RGB\n",
    "        \n",
    "        image = Image.fromarray((image * 255).astype(np.uint8))  # Scale to 0-255 and convert to uint8\n",
    "        print(image.size)  # Print size instead of shape for PIL images\n",
    "            \n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        print(image.shape)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for DenseNet/ResNet\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load train and validation datasets\n",
    "train_dataset = LensDataset(r\"D:\\my_study\\GSOC\\dataset\\dataset\\train\", transform=transform)\n",
    "val_dataset = LensDataset(r\"D:\\my_study\\GSOC\\dataset\\dataset\\val\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "(150, 150)\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i in iter(train_loader):\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dataset/\n",
      "                dataset/\n",
      "                    train/\n",
      "                        no/\n",
      "                        sphere/\n",
      "                        vort/\n",
      "                    val/\n",
      "                        no/\n",
      "                        sphere/\n",
      "                        vort/\n",
      "                __MACOSX/\n",
      "                    dataset/\n",
      "                        train/\n",
      "                        val/\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('D:\\my_study\\GSOC\\dataset'):\n",
    "    level = root.replace('dataset', '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = ' ' * 4 * (level + 1)\n",
    "    # for f in files:\n",
    "    #     print(f\"{sub_indent}{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
